---
title: "Assignment_04"
author: "Megan Xiao"
date: "2025-09-16"
output: github_document
---

```{r}
library(ggplot2)
library(reshape2)
```
## Data Preparation and Cleaning

First, define the 5 vectors: Frequency, BloodPressure, FirstAssess, SecondAssess, and FinalDecision.

Frequency either represents a vector of vital signs frequency or frequency of measurement*. The vector is standardized since the numbers go from 0 to 1.

BloodPressure represents a vector of blood pressure measurements ranging from 32 to 205. Lower values indicate hypotension (low blood pressure) and higher values indicate hypertension (high blood pressure).

FirstAssess, SecondAssess, and FinalDecision represent a vector of the initial binary assessments of Frequency and BloodPressure. 1 equals a bad reading/high indication of blood pressure and 0 equals a good reading/low indication of blood pressure*.

*Since the task did not specify the representation of some columns, I made an estimated guess of their meanings in the context of hospital data.

```{r}
Frequency     <- c(0.6, 0.3, 0.4, 0.4, 0.2, 0.6, 0.3, 0.4, 0.9, 0.2)
BloodPressure <- c(103, 87, 32, 42, 59, 109, 78, 205, 135, 176)
FirstAssess   <- c(1, 1, 1, 1, 0, 0, 0, 0, NA, 1)    # good/low=0, bad/high=1
SecondAssess  <- c(0, 0, 1, 1, 0, 0, 1, 1, 1, 1)    # good/low=0, bad/high=1
FinalDecision <- c(0, 1, 0, 1, 0, 1, 0, 1, 1, 1)    # good/low=0, bad/high=1
```

There is 1 NA value in FirstAssess. We can replace it with the most common value in the vector.

```{r}
FirstAssess[is.na(FirstAssess)] <- 1
FirstAssess
```

We then create a DataFrame using the five vectors.

```{r}
df_hosp <- data.frame(
  Frequency, BloodPressure, FirstAssess,
  SecondAssess, FinalDecision, stringsAsFactors = FALSE
)

```

And inspecting the summary statistics for the DataFrame:
```{r}
summary(df_hosp)
```
Frequency has a similar mean and median, meaning it most likely has a normal distribution. BloodPressure has a higher mean compared to the median, meaning it is skewed to the right. FirstAssess, SecondAssess, and FinalDecision have lower means compared to the median, meaning it is skewed to the left.
The presence of skewness means outliers may overestimate or underestimate the most common measurements. We can use a box plot to determine if there are any outliers.

## Generate Basic Visualizations
```{r}
par(mfrow = c(1,3))
boxplot(BloodPressure ~ FirstAssess,
        data = df_hosp,
        names = c("Low","High"),
        ylab = "Blood Pressure",
        main = "BP by First MD Assessment",
        cex.main = .95)
boxplot(BloodPressure ~ SecondAssess,
  data = df_hosp,
  names = c("Low","High"),
  ylab = "Blood Pressure",
  main = "BP by Second MD Assessment",
  cex.main = .95)
boxplot(
  BloodPressure ~ FinalDecision,
  data = df_hosp,
  names = c("Low","High"),
  ylab = "Blood Pressure",
  main = "BP by Final Decision",
  cex.main = .95)
```
No outliers exist in any of the box plots. In the first assessment, individuals with low, or good readings, had higher blood pressure. The second assessment consisted of more varied blood pressures for those with bad readings. The final decision shows some correlation opposite to the first assessment, where individuals with lower blood pressures had good readings, while individuals with higher blood pressures had bad readings.

Let's also investigate how the differences in frequency variation based on assessment reading.

```{r}
par(mfrow = c(1,3))
boxplot(Frequency ~ FirstAssess,
        data = df_hosp,
        names = c("Low","High"),
        ylab = "Frequency",
        main = "Frequency by First MD Assessment",
        cex.main = .7)
boxplot(Frequency ~ SecondAssess,
  data = df_hosp,
  names = c("Low","High"),
  ylab = "Frequency",
  main = "Frequency by Second MD Assessment",
  cex.main = .7)
boxplot(
  Frequency ~ FinalDecision,
  data = df_hosp,
  names = c("Low","High"),
  ylab = "Frequency",
  main = "Frequency by Final Decision",
  cex.main = .7)
```
The first and second assessment both contain one outlier. Low/bad readings had more varied frequencies. The second assessment had a lower median for high readings compared to the first assessment. However, both readings do not reflect the final decision accurately.

We can also use a scatterplot to view the relationship between blood pressure and frequency.
```{r}
ggplot(data=df_hosp, aes(x=BloodPressure, y=Frequency)) + geom_point()
```
There is a positive weak correlation between frequency and blood pressure; as blood pressure increases, so does frequency.

Lastly, let's see how varied our numerical data for frequency and blood pressure is with a histogram.

```{r}
par(mfrow = c(1,2))
hist(
  df_hosp$Frequency,
  breaks = seq(0, 1, by = 0.3),
  xlab = "Visit Frequency",
  main = "Histogram of Visit Frequency",
  cex.main = .9
)

hist(
  df_hosp$BloodPressure,
  breaks = 5,
  xlab = "Blood Pressure",
  main = "Histogram of Blood Pressure",
  cex.main = .9
)
```
Both frequency and blood pressure are skewed to the right. This means larger values exist, but they aren't common, thus skewing the mean to the right. Common/average values tend to center around the median rather than the mean.

## First Assessment VS Second Assessment for Predicting Final Decision

Which does better at predicting the final decision: the first or second assessment? We can answer this question using a logistic regression algorithm.
Creating a confusion matrix based on a logistic regression model will allow us to see which training set (the first assessment and the second assessment) predicts more accurate results when compared to the test set (the final decision).
I created a function that takes in the training and test sets as arguments. Using a logistic regression model, the algorithm fits a sigmoid line based on the predictors blood pressure and frequency. We can then use the sigmoid line to predict new binomial outputs and compare them to the actual results (the test set).

```{r}
log_reg <- function(train, test){
  train_set <- train #first or second assessment
  test_set <- test #final decision
  
  log_model <- glm(train_set ~ BloodPressure + Frequency, data=df_hosp, family = "binomial") #logistic model (high or low) prediction based on blood pressure AND frequency
  predict_reg <- predict(log_model, type = "response")
  predict_reg <- as.data.frame(predict_reg)
  predict_reg <- round(unlist(predict_reg))
                       
  conf_matrix <- table(test, predict_reg)

  conf_matrix_melted <- as.data.frame(conf_matrix)
  colnames(conf_matrix_melted) <- c("Actual","Predicted","Count")

  conf_matrix_result <- ggplot(conf_matrix_melted, aes(x = Actual, y = Predicted, fill = Count)) +
    geom_tile() +
    geom_text(aes(label = Count), color = "black", size = 6) + 
    scale_fill_gradient(low = "white", high = "blue") +
    theme_minimal()
  return(conf_matrix_result)
}
```

Confusion matrix of FirstAssess:

```{r}
first_train <- df_hosp$FirstAssess
test <- df_hosp$FinalDecision
log_reg(first_train, test)

```

Confusion matrix of SecondAssess:
```{r}
second_train <- df_hosp$SecondAssess
log_reg(second_train, test)
```
## Interpretation and Discussion

## Submission